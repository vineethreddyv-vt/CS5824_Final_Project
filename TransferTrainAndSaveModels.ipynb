{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eCUjWhRtU9r1"
      },
      "outputs": [],
      "source": [
        "#importing all the required libraries\n",
        "\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained VGG16 model with pre-trained weights\n",
        "vgg = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers of the pre-trained VGG16 model\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add new layers at the end of the pre-trained VGG16 model\n",
        "x = Flatten()(vgg.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(4, activation='softmax')(x)\n",
        "\n",
        "# Create the new model\n",
        "model = Model(inputs=vgg.input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8Zt4A_R-KX2",
        "outputId": "6632342a-d285-475f-d993-7bf27a089418"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create dataset for new model training\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/VR Gallery Art\"\n",
        "batch_size = 32\n",
        "img_size = (224, 224)\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255, vertical_flip = True, horizontal_flip= True, validation_split=0.2)\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6C3OYbi0o9E",
        "outputId": "5a9423fe-4f07-4228-c7b7-9ae8dcec4deb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 244 images belonging to 4 classes.\n",
            "Found 59 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdPL_pJi07Ch",
        "outputId": "5d5ee5b3-446b-4306-896a-49a1b9b0b956"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - 114s 15s/step - loss: 3.8524 - accuracy: 0.3302 - val_loss: 0.7171 - val_accuracy: 0.6562\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 101s 15s/step - loss: 2.5143 - accuracy: 0.5613 - val_loss: 0.5244 - val_accuracy: 0.7812\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 99s 14s/step - loss: 1.7408 - accuracy: 0.6509 - val_loss: 0.3502 - val_accuracy: 0.8438\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 106s 16s/step - loss: 1.0737 - accuracy: 0.7075 - val_loss: 0.2532 - val_accuracy: 0.9375\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 106s 16s/step - loss: 0.8070 - accuracy: 0.7925 - val_loss: 0.6102 - val_accuracy: 0.7812\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 103s 15s/step - loss: 0.5106 - accuracy: 0.8393 - val_loss: 0.2950 - val_accuracy: 0.8438\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 99s 14s/step - loss: 0.5594 - accuracy: 0.8302 - val_loss: 0.1772 - val_accuracy: 0.9688\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 111s 16s/step - loss: 0.4294 - accuracy: 0.8491 - val_loss: 0.1867 - val_accuracy: 0.9375\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 100s 15s/step - loss: 0.3213 - accuracy: 0.9104 - val_loss: 0.1976 - val_accuracy: 0.9375\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 100s 14s/step - loss: 0.2960 - accuracy: 0.9198 - val_loss: 0.1523 - val_accuracy: 0.9375\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f30401bd540>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(validation_generator, steps=len(validation_generator))\n",
        "\n",
        "# print the metrics\n",
        "print(\"Test loss:\", loss)\n",
        "print(\"Test accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp_NlsaaGsk6",
        "outputId": "0cf5de55-78b6-4525-edfb-af2989eeb976"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 24s 11s/step - loss: 0.1875 - accuracy: 0.9153\n",
            "Test loss: 0.18753384053707123\n",
            "Test accuracy: 0.9152542352676392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file path for saving the model\n",
        "model_path = '/content/drive/MyDrive/MyModelVGG.h5'\n",
        "\n",
        "model.save(model_path)"
      ],
      "metadata": {
        "id": "RGUGxipbVEjY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}